{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 input files:\n",
    "- training_data.csv: 1st column is the name of the app, the remaining columns are the tf-idf value \n",
    "- training_desc.csv: 1st column is the name of the app, the 2nd columns are the description of the app\n",
    "- training labels.csv: The first column is the app’s name and the second column is for the label\n",
    "- test_data.csv: 1st column is the name of the app, the remaining columns are the tf-idf value\n",
    "\n",
    "There is 1 output file:\n",
    "- “predicted_labels.csv” in the same format as training_labels\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. Import the necessary database and set the path file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "#Please fill in the input folder path and the output folder path\n",
    "input_path = '/Users/ppha/Desktop/UniSyd/Semester3/MachineLearning/Assignment1/assignment1_2017S1'\n",
    "output_path = '/Users/ppha/Desktop/UniSyd/Semester3/MachineLearning/Assignment1/460110536_460114051_460232702/Code/Output'\n",
    "os.chdir(input_path)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "%matplotlib inline\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_train_data = 'training_data.csv'\n",
    "path_label_data= 'training_labels.csv'\n",
    "path_test_data =  'test_data.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Functions to read in the file data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readin_data(line):      \n",
    "    data = line.strip().split(',')\n",
    "    n = len(data)\n",
    "    name_app = str(data[0])\n",
    "    value = data[1:n]\n",
    "    value = np.array(value)\n",
    "    #Convert to only 0 and 1 value \n",
    "    b_value = (value !='0')\n",
    "    b_value = b_value.astype(np.int)\n",
    "    return name_app, b_value\n",
    "        \n",
    "def readin_labels(line):\n",
    "    data = line.strip().split(',')\n",
    "    n = len(data)\n",
    "    name_app = str(data[0])\n",
    "    value = str(data[1:n])\n",
    "    return name_app, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. Read in the training data as train:dict and a training label as label:dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels= OrderedDict()\n",
    "train_labels = open(path_label_data,'r')\n",
    "for line in train_labels.readlines():\n",
    "    name_app, category = readin_labels(line)\n",
    "    labels[name_app] = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 54.040756940841675 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#This execution may take 1 minute\n",
    "train = OrderedDict()\n",
    "train_data = open(path_train_data,'r')\n",
    "start_time = time.time()\n",
    "for line in train_data.readlines():\n",
    "    name_app, tfidf = readin_data(line)\n",
    "    train[name_app] = tfidf\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. Map two dictionaries and convert it to dataframe for better visualization at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#map betweeen two dictionary( so we have key:name_app and value: tfidf, label\n",
    "output = {k:[train.get(k),labels.get(k)] for k in train.keys() | labels.keys()}\n",
    "#convert from dict to dataframe\n",
    "df = pd.DataFrame.from_dict(output, orient ='index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4. Perform 10-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_validation(df, k =10, n=0):\n",
    "    temp = np.array_split(df,k)\n",
    "    test_set= pd.DataFrame()\n",
    "    train_set = list()\n",
    "    for i in range(k):\n",
    "        if i == n: \n",
    "            test_set =temp[i]\n",
    "        else:\n",
    "            train_set.append(temp[i])\n",
    "    train_set = pd.concat(train_set)\n",
    "    return test_set, train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5. Calculate Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def arrange_data(train_df):\n",
    "    #Group each item in the same category together\n",
    "    new_df = train_df.groupby(1,sort=True )[0].apply(list) \n",
    "    new_df = new_df.reset_index()\n",
    "    return new_df\n",
    "\n",
    "def cal_prob(new_df,test,alpha = 1):\n",
    "    #Calculate the number of items in the train_df\n",
    "    count_size = len(new_df) \n",
    "    \n",
    "    X = test[0]\n",
    "    temp = list()\n",
    "    for row in new_df[0]:\n",
    "        \n",
    "        # Calculate the probability of each class\n",
    "        class_prob = np.log(len(row)/count_size)\n",
    "        \n",
    "        #Calculate the number of items in each class\n",
    "        num_items = len(row)\n",
    "        \n",
    "        #Calculate the number of each tfidf that is NOT zero in each line + alpha for smoothing \n",
    "        u = np.array(row).T\n",
    "        count = [(sum(1 for x in i if (x ==1))+alpha) for i in u]\n",
    "        count_attr = np.array(count)\n",
    "        \n",
    "        #Calculate the probability of each tfidf   \n",
    "        attr_prob = np.log(count_attr/num_items) \n",
    "    \n",
    "        prob = [(class_prob + attr_prob.dot(j)) for j in X]\n",
    "        temp.append(prob)\n",
    "        \n",
    "    temp = np.array(temp)\n",
    "    temp = pd.DataFrame(temp)\n",
    "    Category = temp.apply(lambda x: x.argmax(), axis =0)\n",
    "    Category = Category.map(new_df[1])\n",
    "    return Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(train_set,test_set):\n",
    "    new_df = arrange_data(train_set)\n",
    "    cate_prob = cal_prob(new_df,test_set,alpha =1)\n",
    "    return cate_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6. Calculate accuracy, only do this when you want to check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(test_set,cate_prob):\n",
    "    count = 0\n",
    "    for i in range(0,len(cate_prob)):\n",
    "        if test_set[1][i] == cate_prob[i]:\n",
    "            count = count +1\n",
    "    a = count / len(test_set)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#This task might take 10 minutes to compute the accuracy for the whole set\\n#Get the trainset and test set\\nfor i in range(0,10):\\n    n = i\\n    test_set = pd.DataFrame()\\n    train_set = pd.DataFrame()\\n    test_set,train_set = cross_validation(df,k=10,n=n)\\n    start_time = time.time()\\n    cate_prob = predict(train_set,test_set)\\n    acc = accuracy(test_set,cate_prob)\\n    print(i,\\'Accuracy is: \\', acc)\\n    print(i,\"Processing time is %s seconds ---\" % (time.time() - start_time))\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#This task might take 10 minutes to compute the accuracy for the whole set\n",
    "#Get the trainset and test set\n",
    "for i in range(0,10):\n",
    "    n = i\n",
    "    test_set = pd.DataFrame()\n",
    "    train_set = pd.DataFrame()\n",
    "    test_set,train_set = cross_validation(df,k=10,n=n)\n",
    "    start_time = time.time()\n",
    "    cate_prob = predict(train_set,test_set)\n",
    "    acc = accuracy(test_set,cate_prob)\n",
    "    print(i,'Accuracy is: ', acc)\n",
    "    print(i,\"Processing time is %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7. Make prediction for the test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_file = open(path_test_data,'r')\n",
    "test_dict = OrderedDict()\n",
    "for line in test_file.readlines():\n",
    "    name_app, tfidf = readin_data(line)\n",
    "    test_dict[name_app] = tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, k in  enumerate(test_dict.keys()):\n",
    "    u = list()\n",
    "    u.append(test_dict[k])\n",
    "    u.append(i)\n",
    "    test_dict[k] = u\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame.from_dict(test_dict,orient ='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 92.44650602340698 seconds ---\n"
     ]
    }
   ],
   "source": [
    "train_data = df\n",
    "test_data = test_df\n",
    "start_time = time.time()\n",
    "prediction = predict(train_data,test_data)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_file = os.path.join(output_path, 'predicted_labels.csv')         \n",
    "\n",
    "output_test = open(output_file, 'w')\n",
    "for i,k in enumerate(test_dict.keys()):\n",
    "    name = k\n",
    "    pred = prediction[i][2:(len(prediction[i])-2)]\n",
    "    output_test.write(name+','+pred+'\\n')\n",
    "output_test.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
